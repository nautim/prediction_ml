# uploading some background functions and settings
color <- c("#3a5e8cFF", "#10a53dFF", "#541352FF", "#ffcf20FF", "#2f9aa0FF")

color.outline = "#FFFFFF"
#color.outline = "grey90"
color.regline = "#000000"
color.statline = "#4D4D4D"
color.stat = "#000000"
color.background = "grey80"
color.fill = "#000000"

color.fill = "#0000FF"
color.fill2 ="#ADD8E6"
color.fill3 = "#FF8C00"

theme_bg <- function() {
  
  # Generate color palette
  palette <- c("white", 
               "grey70", 
               "black",
               "grey50") # global
  
  color.background
  color.background = palette[1]
  color.grid.major = palette[4]
  color.grid.minor = palette[2]
  color.axis.text = palette[3]
  color.axis.title = palette[3]
  color.title = palette[3]
  
  #  palette_brewer <- brewer.pal("Blues", n=9)
  color.fill <- palette[1]
  color.line <- palette[3]
  
  # Chart elements
  
  theme_bw() +
    
    # Chart region
    
    theme(panel.background=element_rect(fill=color.background, color=color.background)) +
    theme(plot.background=element_rect(fill=color.background, color=color.background)) +
    theme(panel.border=element_rect(color=palette[2],size=.01)) +
    # Axis
    
    theme(axis.line=element_line(color=color.line,size=.2)) +
    
    # Grids
    
    theme(panel.grid.major=element_line(color=color.grid.major,size=.1)) +
    theme(panel.grid.minor=element_line(color=color.grid.major,size=.1)) +
    # theme(axis.ticks=element_blank()) +
    
    # Legend
    
    theme(legend.position=c(0.8,0.2),
          panel.grid.minor =element_blank()) +
    theme(legend.background = element_rect(fill="transparent")) +
    theme(legend.text = element_text(size=4,color=color.axis.title )) +
    
    # Title & axis labels
    
    theme(plot.title=element_text(color=color.title, size=6, vjust=1.25, hjust=0.5, face = "plain")) +
    theme(axis.text.x=element_text(size=6,color=color.axis.text, face = "plain")) +
    theme(axis.text.y=element_text(size=6,color=color.axis.text, face = "plain")) +
    theme(axis.title.x=element_text(size=6,color=color.axis.title, vjust=0, face = "plain")) +
    theme(axis.title.y=element_text(size=6,color=color.axis.title, vjust=1.25, face = "plain")) +
    
    # Margins
    
    theme(plot.margin = unit(c(0.2, 0.2, 0.2, 0.2), "cm"))
}

twoClassSummaryExtended <- function (data, lev = NULL, model = NULL)
{
  lvls <- levels(data$obs)
  rmse <- sqrt(mean((data[, lvls[1]] - ifelse(data$obs == lev[2], 0, 1))^2))
  c(defaultSummary(data, lev, model), "RMSE" = rmse)
}

# createRocPlot <- function(r, file_name,  mywidth_large=12, myheight_large = 9) {
createRocPlot <- function(r, file_name,  myheight_small = 5.625, mywidth_small = 7.5) {
  all_coords <- coords(r, x="all", ret="all", transpose = FALSE)

  roc_plot <- ggplot(data = all_coords, aes(x = fpr, y = tpr)) +
    geom_line(color=color[1], size = 0.7) +
    geom_area(aes(fill = color[4], alpha=0.4), alpha = 0.3, position = 'identity', color = color[1]) +
    scale_fill_viridis(discrete = TRUE, begin=0.6, alpha=0.5, guide = FALSE) +
    xlab("False Positive Rate (1-Specifity)") +
    ylab("True Positive Rate (Sensitivity)") +
    geom_abline(intercept = 0, slope = 1,  linetype = "dotted", col = "black") +
    scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, .1), expand = c(0, 0.01)) +
    scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, .1), expand = c(0.01, 0)) +
    theme_bg()
  #+    theme(axis.text.x = element_text(size=13), axis.text.y = element_text(size=13),
  #        axis.title.x = element_text(size=13), axis.title.y = element_text(size=13))

  #ggsave(plot = roc_plot, paste0(file_name, ".png"),      width=mywidth_small, height=myheight_small, dpi=1200)
  #cairo_ps(filename = paste0(file_name, ".eps"),    #        width = mywidth_small, height = myheight_small, pointsize = 12,    #       fallback_resolution = 1200)
  #print(roc_plot)
  #dev.off()

  roc_plot
}

create_calibration_plot <- function(data, file_name, prob_var, actual_var, y_lab = "Actual event probability" , n_bins = 10, breaks = NULL) {
  
  if (is.null(breaks)) {
    breaks <- seq(0,1,length.out = n_bins + 1)
  }

  binned_data <- data %>%
    mutate(
      prob_bin = cut(!!as.name(prob_var), 
                    breaks = breaks,
                    include.lowest = TRUE)
    ) %>%
    group_by(prob_bin, .drop=FALSE) %>%
    summarise(mean_prob = mean(!!as.name(prob_var)), mean_actual = mean(!!as.name(actual_var)), n = n())

    p <- ggplot(data = binned_data) +
      geom_line(aes(mean_prob, mean_actual), color=color[1], size=0.6, show.legend = TRUE) +
      geom_point(aes(mean_prob,mean_actual), color = color[1], size = 1, shape = 16, alpha = 0.7, show.legend=F, na.rm = TRUE) +
      geom_segment(x=min(breaks), xend=max(breaks), y=min(breaks), yend=max(breaks), color=color[2], size=0.3) +
      theme_bg() +
      labs(x= "Predicted event probability",
           y= y_lab) +
      coord_cartesian(xlim=c(0,1), ylim=c(0,1))+
      expand_limits(x = 0.01, y = 0.01) +
      scale_y_continuous(expand=c(0.01,0.01),breaks=c(seq(0,1,0.1))) +
      scale_x_continuous(expand=c(0.01,0.01),breaks=c(seq(0,1,0.1))) 

    p
}

#createLossPlot
createLossPlot <- function(r, best_coords, file_name,  myheight_small = 5.625, mywidth_small = 7.5) {
  t <- best_coords$threshold[1]
  sp <- best_coords$specificity[1]
  se <- best_coords$sensitivity[1]
  n <- rowSums(best_coords[c("tn", "tp", "fn", "fp")])[1]

  all_coords <- coords(r, x="all", ret="all", transpose = FALSE)
  all_coords <- all_coords %>%
    mutate(loss = (fp*FP + fn*FN)/n)
  l <- all_coords[all_coords$threshold == t, "loss"]

  loss_plot <- ggplot(data = all_coords, aes(x = threshold, y = loss)) +
    geom_line(color=color[1], size=0.7) +
    scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.1)) +
    geom_vline(xintercept = t , color = color[2] ) +
    annotate(geom = "text", x = t, y= min(all_coords$loss),
             label=paste0("best threshold: ", round(t,2)),
             colour=color[2], angle=90, vjust = -1, hjust = -0.5, size = 7) +
    annotate(geom = "text", x = t, y= l,
             label= round(l, 2), hjust = -0.3, size = 7) +
    theme_bg()

  #  ggsave(plot = loss_plot, paste0(file_name,".png"), width=mywidth_small, height=myheight_small, dpi=1200)
  #  cairo_ps(filename = paste0(file_name,".eps"), width = mywidth_small, height = myheight_small, pointsize = 12, fallback_resolution = 1200)
  #  print(loss_plot)
  #  dev.off()

  loss_plot
}

#createRocPlotWithOptimal 
createRocPlotWithOptimal <- function(r, best_coords, file_name,  myheight_small = 5.625, mywidth_small = 7.5) {

  all_coords <- coords(r, x="all", ret="all", transpose = FALSE)
  t <- best_coords$threshold[1]
  sp <- best_coords$specificity[1]
  se <- best_coords$sensitivity[1]

  roc_plot <- ggplot(data = all_coords, aes(x = specificity, y = sensitivity)) +
    geom_line(color=color[1], size=0.7) +
    scale_y_continuous(breaks = seq(0, 1, by = 0.1)) +
    scale_x_reverse(breaks = seq(0, 1, by = 0.1)) +
    geom_point(aes(x = sp, y = se)) +
    annotate(geom = "text", x = sp, y = se,
             label = paste(round(sp, 2),round(se, 2),sep = ", "),
             hjust = 1, vjust = -1, size = 7) +
    theme_bg()
  #  + theme(axis.text.x = element_text(size=20), axis.text.y = element_text(size=20),
  #          axis.title.x = element_text(size=20), axis.title.y = element_text(size=20))

  #  ggsave(plot = roc_plot, paste0(file_name, ".png"),         width=mywidth_small, height=myheight_small, dpi=1200)
  # cairo_ps(filename = paste0(file_name, ".eps"),           width = mywidth_small, height = myheight_small, pointsize = 12,           fallback_resolution = 1200)
  #print(roc_plot)
  #dev.off()

  roc_plot
}

# adding libraries and uploading data
library(data.table)
library(DescTools)
library(margins)
library(caret)
library(tidyverse)
library(knitr)
library(pROC)
library(viridis)
library(rpart)
library(rpart.plot)

data <- fread("/Users/nautim/Desktop/Data and Econometrics/Predictions with ML/cs_bisnode_panel.csv")

## 287829 observations, 48 variables

# preliminary checks of NAs
to_filter <- sapply(data, function(x) sum(is.na(x)))
to_filter[to_filter > 0]

## variables with more than 80% of NAs: COGS, finished_prod, net_dom_sales, net_exp_sales, wages
## they can be deleted

data <- data %>%
  select(-c(COGS, finished_prod, net_dom_sales, net_exp_sales, wages))

####### 
####### sample design
####### 

data_filtered <- data %>%
  filter(year %in% c(2010:2015))
NROW(unique(data_filtered$comp_id))
## 167606 observations now, 39375 unique companies

data_filtered <- data_filtered %>%
  filter(sales >= 1000 & sales <= 50000000)
NROW(unique(data_filtered$comp_id))
## 129491 observations now, 33703 unique companies

####### 
####### label engineering 
####### 

data_filtered_wide <- data_filtered %>% 
  pivot_wider(id_cols = c(comp_id, year), names_from = year, values_from = sales) %>%
  mutate(total_change = `2014` - `2012`,
         perc_change = total_change/`2012`*100)

summary(data_filtered_wide$perc_change)

# imputations
data_filtered_wide <- data_filtered %>% 
  pivot_wider(id_cols = c(comp_id, year), names_from = year, values_from = sales) %>% 
  mutate(imputed = ifelse(is.na(`2012`) == TRUE | is.na(`2014`) == TRUE, 1, 0)) %>%
  mutate(`2012` = ifelse(is.na(`2012`) == TRUE, ifelse(is.na(`2011`) == FALSE & is.na(`2013`) == FALSE, (`2011` + `2013`)/2, NA), `2012`),
         `2012` = ifelse(is.na(`2012`) == TRUE, ifelse(is.na(`2011`) == TRUE & is.na(`2013`) == FALSE, `2013`, NA), `2012`),
         `2014` = ifelse(is.na(`2014`) == TRUE, ifelse(is.na(`2013`) == FALSE & is.na(`2015`) == FALSE, (`2013` + `2015`)/2, NA), `2014`),
         `2014` = ifelse(is.na(`2014`) == TRUE, ifelse(is.na(`2013`) == TRUE & is.na(`2015`) == FALSE, `2015`, NA), `2014`)) %>%
  mutate(total_change = `2014` - `2012`,
         perc_change = total_change/`2012`*100)
summary(data_filtered_wide$perc_change)


data_filtered <- data_filtered_wide %>%
  select(comp_id, imputed, total_change, perc_change) %>%
  right_join(data_filtered, by = "comp_id")

data_filtered <- data_filtered[!is.na(data_filtered$perc_change),]
summary(data_filtered$perc_change)
NROW(unique(data_filtered$comp_id))
## 102932 observations now, 19662 firms

# visualising dependent variable
quantile(data_filtered$perc_change, probs = c(0.65))

data_filtered %>%
  filter(perc_change <= 1000) %>%
  ggplot(aes(x = perc_change)) + geom_density() +
  geom_vline(xintercept = 35, color = "blue")
  
# creating fast growth binary - main dependent variable
data_filtered <- data_filtered %>%
  mutate(fast_growth = ifelse(perc_change >= 35, 1, 0))

data_filtered$fast_growth_f <- as.factor(data_filtered$fast_growth)

summary(data_filtered$fast_growth)
table(data_filtered$fast_growth_f)
data_filtered %>%
  select(comp_id, fast_growth) %>%
  unique() %>%
  group_by(fast_growth) %>%
  dplyr::summarize(n_firms = n())


####### 
####### feature engineering 
####### 

## amort
data_filtered %>%
  ggplot(aes(x = amort)) + geom_density()
summary(data_filtered$amort) 
# 199 NAs - not so many, so can impute with a median; variables under 0 can be changed to 0 with flagging it

data_filtered <- data_filtered %>%
  mutate(amort =  ifelse(is.na(amort), median(amort, na.rm = T), amort),
         amort_flag = ifelse(amort < 0, 1, 0),
         amort = ifelse(amort < 0, 0, amort),
         ln_amort = log(amort + 1))
data_filtered %>%
  ggplot(aes(x = ln_amort)) + geom_density()

summary(data_filtered$flag_error)

# flagging if assets < 0

data_filtered <- data_filtered %>%
  mutate(flag_asset_problem =  ifelse(intang_assets < 0 | curr_assets < 0 | fixed_assets < 0 | liq_assets < 0 | tang_assets < 0, 1, 0))

## curr_assets
data_filtered %>%
  ggplot(aes(x = curr_assets)) + geom_density()
summary(data_filtered$curr_assets) 
# 19 NAs - not so many, so again can impute with a median; variables under 0 can be changed to 0 with flagging it

data_filtered <- data_filtered %>%
  mutate(curr_assets =  ifelse(is.na(curr_assets), median(curr_assets, na.rm = T), curr_assets),
         curr_assets = ifelse(curr_assets < 0, 0, curr_assets),
         ln_curr_assets = log(curr_assets + 1))
data_filtered %>%
  ggplot(aes(x = ln_curr_assets)) + geom_density()

## fixed_assets
data_filtered %>%
  ggplot(aes(x = fixed_assets)) + geom_density()
summary(data_filtered$fixed_assets) 
# 19 NAs - not so many, so again can impute with a median; variables under 0 can be changed to 0 with flagging it

data_filtered <- data_filtered %>%
  mutate(fixed_assets =  ifelse(is.na(fixed_assets), median(fixed_assets, na.rm = T), fixed_assets),
         fixed_assets = ifelse(fixed_assets < 0, 0, fixed_assets),
         ln_fixed_assets = log(fixed_assets + 1))
data_filtered %>%
  ggplot(aes(x = ln_fixed_assets)) + geom_density()

## intang_assets
data_filtered %>%
  ggplot(aes(x = intang_assets)) + geom_density()
summary(data_filtered$intang_assets) 
# 19 NAs - not so many, so again can impute with a median; variables under 0 can be changed to 0 with flagging it

data_filtered <- data_filtered %>%
  mutate(intang_assets =  ifelse(is.na(intang_assets), median(intang_assets, na.rm = T), intang_assets),
         intang_assets = ifelse(intang_assets < 0, 0, intang_assets),
         ln_intang_assets = log(intang_assets + 1))
data_filtered %>%
  ggplot(aes(x = ln_intang_assets)) + geom_density()

## liq_assets
data_filtered %>%
  ggplot(aes(x = liq_assets)) + geom_density()
summary(data_filtered$liq_assets) 
# 19 NAs - not so many, so again can impute with a median; variables under 0 can be changed to 0 with flagging it

data_filtered <- data_filtered %>%
  mutate(liq_assets =  ifelse(is.na(liq_assets), median(liq_assets, na.rm = T), liq_assets),
         liq_assets = ifelse(liq_assets < 0, 0, liq_assets),
         ln_liq_assets = log(liq_assets + 1))
data_filtered %>%
  ggplot(aes(x = ln_liq_assets)) + geom_density()

## tang_assets
data_filtered %>%
  ggplot(aes(x = tang_assets)) + geom_density()
summary(data_filtered$tang_assets) 
# 19 NAs - not so many, so again can impute with a median; variables under 0 can be changed to 0 with flagging it

data_filtered <- data_filtered %>%
  mutate(tang_assets =  ifelse(is.na(tang_assets), median(tang_assets, na.rm = T), tang_assets),
         tang_assets = ifelse(tang_assets < 0, 0, tang_assets),
         ln_tang_assets = log(tang_assets + 1))
data_filtered %>%
  ggplot(aes(x = ln_tang_assets)) + geom_density()
  
# flagging if other non-negative variables < 0

data_filtered <- data_filtered %>%
  mutate(flag_error =  ifelse(curr_liab < 0 | extra_exp < 0 | extra_inc < 0 | inventories < 0 | material_exp < 0 | personnel_exp < 0 | subscribed_cap < 0, 1, 0))

# curr_liab
data_filtered %>%
  ggplot(aes(x = curr_liab)) + geom_density()
summary(data_filtered$curr_liab) 
# 19 NAs - not so many, so again can impute with a median; variables under 0 can be changed to 0 with flagging it

data_filtered <- data_filtered %>%
  mutate(curr_liab =  ifelse(is.na(curr_liab), median(curr_liab, na.rm = T), curr_liab),
         curr_liab = ifelse(curr_liab < 0, 0, curr_liab),
         ln_curr_liab = log(curr_liab + 1))
data_filtered %>%
  ggplot(aes(x = ln_curr_liab)) + geom_density()

## extra_exp
data_filtered %>%
  ggplot(aes(x = extra_exp)) + geom_density()
summary(data_filtered$extra_exp) 
# 3 NAs - not so many, so again can impute with a median; variables under 0 can be changed to 0 with flagging it

data_filtered <- data_filtered %>%
  mutate(extra_exp =  ifelse(is.na(extra_exp), median(extra_exp, na.rm = T), extra_exp),
         extra_exp = ifelse(extra_exp < 0, 0, extra_exp),
         ln_extra_exp = log(extra_exp + 1))
data_filtered %>%
  ggplot(aes(x = ln_extra_exp)) + geom_density()

## extra_inc
data_filtered %>%
  ggplot(aes(x = extra_inc)) + geom_density()
summary(data_filtered$extra_inc) 
# 3 NAs - not so many, so again can impute with a median; variables under 0 can be changed to 0 with flagging it

data_filtered <- data_filtered %>%
  mutate(extra_inc =  ifelse(is.na(extra_inc), median(extra_inc, na.rm = T), extra_inc),
         extra_inc = ifelse(extra_inc < 0, 0, extra_inc),
         ln_extra_inc = log(extra_inc + 1))
data_filtered %>%
  ggplot(aes(x = ln_extra_inc)) + geom_density()

## inc_bef_tax
data_filtered %>%
  ggplot(aes(x = inc_bef_tax)) + geom_density()
summary(data_filtered$inc_bef_tax) 

# in this case, I decided to standartise and then winsorized it
data_filtered <- data_filtered %>%
  mutate(inc_bef_tax_st = (inc_bef_tax - mean(inc_bef_tax))/sd(inc_bef_tax))

data_filtered$inc_bef_tax_st <- Winsorize(data_filtered$inc_bef_tax_st, minval = NULL, maxval = NULL, probs = c(0.05, 0.95),
                  na.rm = FALSE, type = 7)

data_filtered %>%
  ggplot(aes(x = inc_bef_tax_st)) + geom_density()


## inventories
data_filtered %>%
  ggplot(aes(x = inventories)) + geom_density()
summary(data_filtered$inventories) 
# 19 NAs - not so many, so again can impute with a median; variables under 0 can be changed to 0 with flagging it

data_filtered <- data_filtered %>%
  mutate(inventories =  ifelse(is.na(inventories), median(inventories, na.rm = T), inventories),
         inventories = ifelse(inventories < 0, 0, inventories),
         ln_inventories = log(inventories + 1))
data_filtered %>%
  ggplot(aes(x = ln_inventories)) + geom_density()


## material_exp
data_filtered %>%
  ggplot(aes(x = material_exp)) + geom_density()
summary(data_filtered$material_exp) 
# 199 NAs - not so many, so again can impute with a median; variables under 0 can be changed to 0 with flagging it

data_filtered <- data_filtered %>%
  mutate(material_exp =  ifelse(is.na(material_exp), median(material_exp, na.rm = T), material_exp),
         material_exp = ifelse(material_exp < 0, 0, material_exp),
         ln_material_exp = log(material_exp + 1))
data_filtered %>%
  ggplot(aes(x = ln_material_exp)) + geom_density()

## personnel_exp
data_filtered %>%
  ggplot(aes(x = personnel_exp)) + geom_density()
summary(data_filtered$personnel_exp) 
# 199 NAs - not so many, so again can impute with a median; variables under 0 can be changed to 0 with flagging it

data_filtered <- data_filtered %>%
  mutate(personnel_exp =  ifelse(is.na(personnel_exp), median(personnel_exp, na.rm = T), personnel_exp),
         personnel_exp = ifelse(personnel_exp < 0, 0, personnel_exp),
         ln_personnel_exp = log(personnel_exp + 1))
data_filtered %>%
  ggplot(aes(x = ln_personnel_exp)) + geom_density()

## profit_loss_year
data_filtered %>%
  ggplot(aes(x = profit_loss_year)) + geom_density()
summary(data_filtered$profit_loss_year) 
# 25 NAs - not so many, so again can impute with a median; standartisation and winsorising

data_filtered <- data_filtered %>%
  mutate(profit_loss_year =  ifelse(is.na(profit_loss_year), median(profit_loss_year, na.rm = T), profit_loss_year),
         profit_loss_year_st = (profit_loss_year - mean(profit_loss_year))/sd(profit_loss_year))

data_filtered$profit_loss_year_st <- Winsorize(data_filtered$profit_loss_year_st, minval = NULL, maxval = NULL, probs = c(0.05, 0.95),
                                          na.rm = FALSE, type = 7)

data_filtered %>%
  ggplot(aes(x = profit_loss_year_st)) + geom_density()

## subscribed_cap
data_filtered %>%
  ggplot(aes(x = subscribed_cap)) + geom_density()
summary(data_filtered$subscribed_cap) 
# 19 NAs - not so many, so again can impute with a median; variables under 0 can be changed to 0 with flagging it

data_filtered <- data_filtered %>%
  mutate(subscribed_cap =  ifelse(is.na(subscribed_cap), median(subscribed_cap, na.rm = T), subscribed_cap),
         subscribed_cap = ifelse(subscribed_cap < 0, 0, subscribed_cap),
         ln_subscribed_cap = log(subscribed_cap + 1))
data_filtered %>%
  ggplot(aes(x = ln_subscribed_cap)) + geom_density()


## set of numeric variables
financial_perform <- c("ln_amort", "amort_flag", "ln_curr_assets", "ln_fixed_assets", "ln_intang_assets", "ln_liq_assets", "ln_tang_assets", "flag_asset_problem", "ln_curr_liab", "ln_extra_exp", "ln_extra_inc", "inc_bef_tax_st", "ln_inventories", "ln_material_exp", "ln_personnel_exp", "profit_loss_year_st", "ln_subscribed_cap", "flag_error")


## set of variables related to the people

### ceo_count
data_filtered %>%
  ggplot(aes(x = ceo_count)) + geom_bar()
summary(data_filtered$ceo_count)

# let's unite all categories with 3 and more CEOs together; for NAs, assume it equals to the median (1 CEO) + flag them
data_filtered <- data_filtered %>%
  mutate(ceo_count_flag = ifelse(is.na(ceo_count), 1, 0),
         ceo_count = ifelse(is.na(ceo_count), median(ceo_count, na.rm = T), ceo_count),
         ceo_count = as.factor(ifelse(ceo_count >= 3, 3, ceo_count)))

data_filtered %>%
  ggplot(aes(x = ceo_count)) + geom_bar()

### foreign CEO share
data_filtered %>%
  ggplot(aes(x = foreign)) + geom_density()
summary(data_filtered$foreign)

# let's transform NAs to mean (since it is share) and flag them
data_filtered <- data_filtered %>%
  mutate(foreign_flag = ifelse(is.na(foreign), 1, 0),
         foreign = ifelse(is.na(foreign), mean(foreign, na.rm = T), foreign))


data_filtered %>%
  ggplot(aes(x = foreign)) + geom_bar()

### female CEO share
data_filtered %>%
  ggplot(aes(x = female)) + geom_density()
summary(data_filtered$female)

# in the same way, let's transform NAs to mean (since it is share) and flag them
data_filtered <- data_filtered %>%
  mutate(female_flag = ifelse(is.na(female), 1, 0),
         female = ifelse(is.na(female), mean(female, na.rm = T), female))

data_filtered %>%
  ggplot(aes(x = female)) + geom_bar()

# in the same way, let's transform NAs to median and flag them
data_filtered <- data_filtered %>%
  mutate(birth_year_flag = ifelse(is.na(birth_year), 1, 0),
         birth_year = ifelse(is.na(birth_year), mean(birth_year, na.rm = T), birth_year),
         birth_year = floor(birth_year),
         birth_year = as.factor(birth_year))

data_filtered %>%
  ggplot(aes(x = birth_year)) + geom_bar()

### inoffice_days
data_filtered %>%
  ggplot(aes(x = inoffice_days)) + geom_bar()
table(data_filtered$inoffice_days)
summary(data_filtered$inoffice_days)

# in the same way, let's transform NAs to median and flag them
data_filtered <- data_filtered %>%
  mutate(inoffice_days_flag = ifelse(is.na(inoffice_days), 1, 0),
         inoffice_days = ifelse(is.na(inoffice_days), mean(inoffice_days, na.rm = T), inoffice_days))

data_filtered %>%
  ggplot(aes(x = inoffice_days)) + geom_bar()

### gender
data_filtered %>%
  ggplot(aes(x = gender)) + geom_bar()
table(data_filtered$gender)
summary(data_filtered$gender)

# here, I think NAs can be used as a reference category
data_filtered$gender <- fct_recode(data_filtered$gender, "zero" = "")
data_filtered <- data_filtered %>%
  mutate(gender = as.factor(gender),
         gender = relevel(gender, ref = "zero")) 

### origin
data_filtered %>%
  ggplot(aes(x = origin)) + geom_bar()
table(data_filtered$origin)
summary(data_filtered$origin)

# NAs also can be used as a reference category
data_filtered$origin <- fct_recode(data_filtered$origin, "zero" = "")
data_filtered <- data_filtered %>%
  mutate(origin = as.factor(origin),
         origin = relevel(origin, ref = "zero"))

hr <- c("ceo_count", "ceo_count_flag", "foreign", "female",
        "inoffice_days", "gender", "origin")

### urban_m
data_filtered %>%
  ggplot(aes(x = urban_m)) + geom_bar()

data_filtered <- data_filtered %>%
  mutate(urban_m = as.factor(urban_m),
         urban_m = fct_recode(urban_m, "capital" = "1", "other big" = "2", "other" = "3"))

data_filtered %>%
  ggplot(aes(x = urban_m)) + geom_bar()

### region_m
data_filtered %>%
  ggplot(aes(x = region_m)) + geom_bar()
table(data_filtered$region_m) # let's also use NAs as references

data_filtered <- data_filtered %>%
  mutate(region_m = factor(region_m, levels = c("Central", "East", "West"))) %>%
  drop_na(region_m) # delete NAs

data_filtered %>%
  ggplot(aes(x = region_m)) + geom_bar()

geography <- c("urban_m", "region_m")

### year
data_filtered %>%
  ggplot(aes(x = year)) + geom_bar()
data_filtered$year <- as.factor(data_filtered$year)
summary(data_filtered$year)

### category
data_filtered %>%
  ggplot(aes(x = ind2)) + geom_bar()
## too many categories, some are too specific and small - need to make them "more common"; 34 NAs can create another category
data_filtered <- data_filtered %>%
  mutate(ind2_cat = ind2 %>%
           ifelse(. > 56, 60, .)  %>%
           ifelse(. < 26, 20, .) %>%
           ifelse(. < 55 & . > 35, 40, .) %>%
           ifelse(. == 31, 30, .) %>%
           ifelse(is.na(.), 99, .)
           )
data_filtered$ind2_cat <- as.factor(data_filtered$ind2_cat)
table(data_filtered$ind2_cat)

### imputed DV
data_filtered %>%
  ggplot(aes(x = imputed)) + geom_bar()
data_filtered$imputed <- as.factor(data_filtered$imputed)
summary(data_filtered$imputed)

## set of fe variables
fe <- c("year", "ind2_cat", "imputed")

# adding polynomials and interactions
## sq is needed
ggplot(data = data_filtered, aes(x = ln_amort, y = as.numeric(fast_growth))) +
  geom_point(size = 2,  shape = 20, stroke=2, fill = "blue", color = "blue") +
  geom_smooth(method = "lm", formula = y ~ poly(x,2), color = color[4], se = F, size = 1)+
  geom_smooth(method = "loess", se = F, colour = color[5], size = 1.5, span = 0.9) +
  labs(x = "ln_amort", y = "fast_growth") +
  theme_bg()

## sq is needed
ggplot(data = data_filtered, aes(x = ln_curr_assets, y = as.numeric(fast_growth))) +
  geom_point(size = 2,  shape = 20, stroke=2, fill = "blue", color = "blue") +
  geom_smooth(method = "lm", formula = y ~ x, color = color[4], se = F, size = 1)+
  geom_smooth(method = "loess", se = F, colour = color[5], size = 1.5, span = 0.9) +
  labs(x = "ln_curr_assets", y = "fast_growth") +
  theme_bg()

## it is better to include all squares, LASSO will decide

data_filtered <- data_filtered %>%
  mutate(ln_amort2 = ln_amort^2,
         ln_curr_assets2 = ln_curr_assets^2,
         ln_curr_liab2 = ln_curr_liab^2,
         ln_extra_exp2 = ln_extra_exp^2,
         ln_extra_inc2 = ln_extra_inc^2,
         ln_fixed_assets2 = ln_fixed_assets^2,
         inc_bef_tax_st2 = inc_bef_tax_st^2,
         ln_intang_assets2 = ln_intang_assets^2,
         ln_inventories2 = ln_inventories^2,
         ln_liq_assets2 = ln_liq_assets^2,
         ln_material_exp2 = ln_material_exp^2,
         ln_personnel_exp2 = ln_personnel_exp^2,
         profit_loss_year_st2 = profit_loss_year_st^2,
         ln_tang_assets2 = ln_tang_assets^2,
         ln_subscribed_cap2 = ln_subscribed_cap^2)

polynomials <- c("ln_amort2", "ln_curr_assets2", "ln_curr_liab2", "ln_extra_exp2",
                 "ln_extra_inc2", "ln_fixed_assets2", 
                 "inc_bef_tax_st2", "ln_intang_assets2", "ln_inventories2",
                 "ln_liq_assets2", "ln_material_exp2", "ln_personnel_exp2",
                 "profit_loss_year_st2", "ln_tang_assets2", "ln_subscribed_cap2")

interactions1 <- c("urban_m*ln_extra_exp", "urban_m*ln_personnel_exp", "urban_m*inc_bef_tax_st", "urban_m*ln_fixed_assets2",
                  "origin*ln_extra_exp", "origin*ln_personnel_exp", "origin*inc_bef_tax_st", "origin*ln_fixed_assets2",
                  "region_m*ln_extra_exp", "region_m*ln_personnel_exp", "region_m*inc_bef_tax_st", "region_m*ln_fixed_assets2",
                  "gender*ln_extra_exp", "gender*ln_personnel_exp", "gender*inc_bef_tax_st", "gender*ln_fixed_assets2")

interactions2 <- c("foreign*ln_extra_exp", "foreign*ln_personnel_exp", "foreign*inc_bef_tax_st", "foreign*ln_fixed_assets2",
                   "female*ln_extra_exp", "female*ln_personnel_exp", "female*inc_bef_tax_st", "female*ln_fixed_assets2")
                   
####### 
####### model building 
####### 

X1 <- c(financial_perform)
X2 <- c(financial_perform, hr)
X3 <- c(financial_perform, hr, geography)
X4 <- c(financial_perform, hr, geography, fe)
X5 <- c(financial_perform, hr, geography, fe, polynomials)
X6 <- c(financial_perform, hr, geography, fe, polynomials, interactions1, interactions2)

# for LASSO
logitvars <- c(financial_perform, hr, geography, fe, polynomials, interactions1, interactions2)
  
# for random forest
rfvars  <-  c(financial_perform, hr, geography, fe)

# ols - model 1
ols_modelx1 <- lm(formula(paste0("fast_growth ~ ", paste0(X1, collapse = " + "))),
                data = data_filtered)
summary(ols_modelx1)

# logit - model 1
glm_modelx1 <- glm(formula(paste0("fast_growth_f ~", paste0(X1, collapse = " + "))),
                   data = data_filtered, family = "binomial")
summary(glm_modelx1)

# Check model X2
glm_modelx2 <- glm(formula(paste0("fast_growth_f ~", paste0(X2, collapse = " + "))),
                 data = data_filtered, family = "binomial")
summary(glm_modelx2)

#calculate average marginal effects (dy/dx) for logit
mx2 <- margins(glm_modelx2, vce = "none")

sum_table <- summary(glm_modelx2) %>%
  coef() %>%
  as.data.frame() %>%
  select(Estimate) %>%
  mutate(factor = row.names(.)) %>%
  merge(summary(mx2)[,c("factor","AME")])
  
kable(x = sum_table, format = "html", digits = 3,
    col.names = c("Variable", "Coefficient", "dx/dy"),
    caption = "Average Marginal Effects (dy/dx) for Logit Model")
    
ols_modelx3 <- lm(formula(paste0("fast_growth ~", paste0(X3, collapse = " + "))),
                data = data_filtered)
summary(ols_modelx3)

glm_modelx3 <- glm(formula(paste0("fast_growth_f ~", paste0(X3, collapse = " + "))),
                 data = data_filtered, family = "binomial")
summary(glm_modelx3)

ols_modelx4 <- lm(formula(paste0("fast_growth ~", paste0(X4, collapse = " + "))),
                data = data_filtered)
summary(ols_modelx4)

glm_modelx4 <- glm(formula(paste0("fast_growth_f ~", paste0(X4, collapse = " + "))),
                 data = data_filtered, family = "binomial")
summary(glm_modelx4)

#calculate average marginal effects (dy/dx) for logit
# vce="none" makes it run much faster, here we do not need variances

m <- margins(glm_modelx4, vce = "none")

sum_table2 <- summary(glm_modelx4) %>%
  coef() %>%
  as.data.frame() %>%
  select(Estimate, `Std. Error`) %>%
  mutate(factor = row.names(.)) %>%
  merge(summary(m)[,c("factor","AME")])

kable(x = sum_table2, format = "html", digits = 3,
      col.names = c("Variable", "Coefficient", "SE", "dx/dy"),
      caption = "Average Marginal Effects (dy/dx) for Logit Model")
      

####### 
####### analysing models and probability prediction
####### 

set.seed(1234)

data_filtered <- data_filtered %>%
  drop_na(flag_asset_problem, flag_error)

data_filtered <- data_filtered %>% 
  mutate(fast_growth_f = factor(fast_growth_f, 
                        labels = make.names(levels(fast_growth_f))))

train_indices <- as.integer(createDataPartition(data_filtered$fast_growth_f, p = 0.8, list = FALSE))
data_train <- data_filtered[train_indices, ]
data_holdout <- data_filtered[-train_indices, ]

dim(data_train)
dim(data_holdout)

# 5 cross-validation

train_control <- trainControl(
  method = "cv",
  number = 5,
  classProbs = TRUE,
  summaryFunction = twoClassSummaryExtended,
  savePredictions = TRUE)

logit_model_vars <- list("X1" = X1, "X2" = X2, "X3" = X3, "X4" = X4, "X5" = X5, "X6" = X6)

CV_RMSE_folds <- list()
logit_models <- list()


for (model_name in names(logit_model_vars)) {

  features <- logit_model_vars[[model_name]]

  set.seed(1234)
  glm_model <- train(
    formula(paste0("fast_growth_f ~", paste0(features, collapse = " + "))),
    method = "glm",
    data = data_train,
    family = binomial,
    trControl = train_control
  )

  logit_models[[model_name]] <- glm_model
  # Calculate RMSE on test for each fold
  CV_RMSE_folds[[model_name]] <- glm_model$resample[,c("Resample", "RMSE")]

}

# Logit lasso -----------------------------------------------------------

lambda <- 10^seq(-1, -4, length = 10)
grid <- expand.grid("alpha" = 1, lambda = lambda)

set.seed(1234)
system.time({
  logit_lasso_model <- train(
    formula(paste0("fast_growth_f ~", paste0(logitvars, collapse = " + "))),
    data = data_train,
    method = "glmnet",
    preProcess = c("center", "scale"),
    family = "binomial",
    trControl = train_control,
    tuneGrid = grid,
    na.action = na.exclude
  )
})

tuned_logit_lasso_model <- logit_lasso_model$finalModel
best_lambda <- logit_lasso_model$bestTune$lambda
logit_models[["LASSO"]] <- logit_lasso_model
lasso_coeffs <- as.matrix(coef(tuned_logit_lasso_model, best_lambda))

CV_RMSE_folds[["LASSO"]] <- logit_lasso_model$resample[,c("Resample", "RMSE")]

# Draw ROC Curve and calculate AUC for each folds --------------------------------
CV_AUC_folds <- list()

for (model_name in names(logit_models)) {

  auc <- list()
  model <- logit_models[[model_name]]
  for (fold in c("Fold1", "Fold2", "Fold3", "Fold4", "Fold5")) {
    cv_fold <-
      model$pred %>%
      filter(Resample == fold)

    roc_obj <- roc(cv_fold$obs, cv_fold$X1)
    auc[[fold]] <- as.numeric(roc_obj$auc)
  }

  CV_AUC_folds[[model_name]] <- data.frame("Resample" = names(auc),
                                              "AUC" = unlist(auc))
}

# For each model: average RMSE and average AUC for models ----------------------------------

CV_RMSE <- list()
CV_AUC <- list()

for (model_name in names(logit_models)) {
  CV_RMSE[[model_name]] <- mean(CV_RMSE_folds[[model_name]]$RMSE)
  CV_AUC[[model_name]] <- mean(CV_AUC_folds[[model_name]]$AUC)
}

# We have 6 models, (5 logit and the logit lasso). For each we have a 5-CV RMSE and AUC.
# We pick our preferred model based on that. -----------------------------------------------

nvars <- lapply(logit_models, FUN = function(x) length(x$coefnames))
nvars[["LASSO"]] <- sum(lasso_coeffs != 0)

logit_summary1 <- data.frame("Number of predictors" = unlist(nvars),
                             "CV RMSE" = unlist(CV_RMSE),
                             "CV AUC" = unlist(CV_AUC))

kable(x = logit_summary1, format = "html", booktabs = TRUE,  digits = 3, row.names = TRUE,
      linesep = "", col.names = c("Number of predictors","CV RMSE","CV AUC")) 

best_logit_no_loss <- logit_models[["X6"]]

logit_predicted_probabilities_holdout <- predict(best_logit_no_loss, newdata = data_holdout, type = "prob")
data_holdout[,"best_logit_no_loss_pred"] <- logit_predicted_probabilities_holdout[,"X1"]
RMSE(data_holdout[, "best_logit_no_loss_pred", drop=TRUE], data_holdout$default)

# discrete ROC (with thresholds in steps)
thresholds <- seq(0.05, 0.75, by = 0.05)

cm <- list()
true_positive_rates <- c()
false_positive_rates <- c()
for (thr in thresholds) {
  holdout_prediction <- ifelse(data_holdout[,"best_logit_no_loss_pred"] < thr, "X0", "X1") %>%
    factor(levels = c("X0", "X1"))
  cm_thr <- confusionMatrix(holdout_prediction, data_holdout$fast_growth_f)$table
  cm[[as.character(thr)]] <- cm_thr
  true_positive_rates <- c(true_positive_rates, cm_thr["X1", "X1"] /
                             (cm_thr["X1", "X1"] + cm_thr["X0", "X1"]))
  false_positive_rates <- c(false_positive_rates, cm_thr["X1", "X0"] /
                              (cm_thr["X1", "X0"] + cm_thr["X0", "X0"]))
}

tpr_fpr_for_thresholds <- tibble(
  "threshold" = thresholds,
  "true_positive_rate" = true_positive_rates,
  "false_positive_rate" = false_positive_rates
)

discrete_roc_plot <- ggplot(
  data = tpr_fpr_for_thresholds,
  aes(x = false_positive_rate, y = true_positive_rate, color = threshold)) +
  labs(x = "False positive rate (1 - Specificity)", y = "True positive rate (Sensitivity)") +
  geom_point(size=2, alpha=0.8) +
  scale_color_viridis(option = "D", direction = -1) +
  scale_x_continuous(expand = c(0.01,0.01), limit=c(0,1), breaks = seq(0,1,0.1)) +
  scale_y_continuous(expand = c(0.01,0.01), limit=c(0,1), breaks = seq(0,1,0.1)) +
  theme_bg() +
  theme(legend.position ="right") +
  theme(legend.title = element_text(size = 4), 
        legend.text = element_text(size = 4),
        legend.key.size = unit(.4, "cm")) 
discrete_roc_plot

# continuous ROC on holdout with best model (Logit 4) -------------------------------------------

roc_obj_holdout <- roc(data_holdout$fast_growth_f, data_holdout$best_logit_no_loss_pred)

createRocPlot(roc_obj_holdout, "best_logit_no_loss_roc_plot_holdout")

# Confusion table with different tresholds ----------------------------------------------------------

# default: the threshold 0.5 is used to convert probabilities to binary classes
logit_class_prediction <- predict(best_logit_no_loss, newdata = data_holdout)
summary(logit_class_prediction)

# confusion matrix: summarize different type of errors and successfully predicted cases
# positive = "yes": explicitly specify the positive case
cm_object1 <- confusionMatrix(logit_class_prediction, data_holdout$fast_growth_f, positive = "X1")
cm1 <- cm_object1$table
cm1

# we can apply different thresholds

# 0.5 same as before
holdout_prediction <-
  ifelse(data_holdout$best_logit_no_loss_pred < 0.4, "X0", "X1") %>%
  factor(levels = c("X0", "X1"))
cm_object1b <- confusionMatrix(holdout_prediction, data_holdout$fast_growth_f)
cm1b <- cm_object1b$table
cm1b

# a sensible choice: mean of predicted probabilities
mean_predicted_default_prob <- mean(data_holdout$best_logit_no_loss_pred)
mean_predicted_default_prob
holdout_prediction <-
  ifelse(data_holdout$best_logit_no_loss_pred < mean_predicted_default_prob, "X0", "X1") %>%
  factor(levels = c("X0", "X1"))
cm_object2 <- confusionMatrix(holdout_prediction, data_holdout$fast_growth_f)
cm2 <- cm_object2$table
cm2

create_calibration_plot(data_holdout,                    
  prob_var = "best_logit_no_loss_pred", 
  actual_var = "fast_growth",
  n_bins = 15)


